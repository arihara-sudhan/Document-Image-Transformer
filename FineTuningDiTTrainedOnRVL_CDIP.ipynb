{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc5637e3",
   "metadata": {},
   "source": [
    "# FINE-TUNING DiT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a705bb1b",
   "metadata": {},
   "source": [
    "# ![https://images.pexels.com/photos/357514/pexels-photo-357514.jpeg?cs=srgb&dl=pexels-pixabay-357514.jpg&fm=jpg](https://images.pexels.com/photos/357514/pexels-photo-357514.jpeg?cs=srgb&dl=pexels-pixabay-357514.jpg&fm=jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a939ca3",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b2061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from transformers import AutoModelForImageClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a990b4b9",
   "metadata": {},
   "source": [
    "# CONFIGS + PREPROCESSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d53b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForImageClassification.from_pretrained(\"microsoft/dit-base-finetuned-rvlcdip\")\n",
    "num_classes = 4\n",
    "model.avg_pooling = torch.nn.AdaptiveAvgPool2d(1)\n",
    "model.classifier = torch.nn.Linear(model.config.hidden_size, num_classes)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to fit the model input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize images\n",
    "])\n",
    "\n",
    "data_folder = \"./Datasets/DOCS/train/\"\n",
    "train_dataset = ImageFolder(data_folder, transform=transform, is_valid_file=lambda filename: not filename.endswith('.ipynb_checkpoints'))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': model.base_model.parameters(), 'lr': 1e-6},  # Pre-trained layers\n",
    "    {'params': model.classifier.parameters()}  # New classifier layer\n",
    "], lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1d1ce7",
   "metadata": {},
   "source": [
    "# TRAIN IT UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ba4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for step, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, return_dict=True)\n",
    "        logits = outputs.logits\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7152e6f1",
   "metadata": {},
   "source": [
    "# TEST IT UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d92a7600",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"./Datasets/DOCS/test/\"\n",
    "test_dataset = ImageFolder(data_folder, transform=transform, is_valid_file=lambda filename: not filename.endswith('.ipynb_checkpoints'))\n",
    "\n",
    "if len(test_dataset) == 0:\n",
    "    raise ValueError(\"No images found in the dataset. Please check the 'test' subfolders.\")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cd9da3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs, return_dict=True)\n",
    "        logits = outputs.logits\n",
    "        predicted_labels = logits.argmax(dim=1)\n",
    "        total_correct += (predicted_labels == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "accuracy = total_correct / total_samples\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ebb6a8",
   "metadata": {},
   "source": [
    "# MANGALAM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
