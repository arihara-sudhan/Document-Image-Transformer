{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7661c93b-c8e6-43d4-8a10-a956f70cd89b",
   "metadata": {},
   "source": [
    "IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65a6e64f-5dac-4129-b656-23966848e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.optim import Adam,lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.nn.parallel import DataParallel\n",
    "import torchvision.models as models\n",
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import faiss\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "from transformers import AutoModel, AutoFeatureExtractor\n",
    "from prettytable import PrettyTable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d417550-50b5-4392-b4c7-16b632337618",
   "metadata": {},
   "source": [
    "Document Image Transformer - Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf74b77e-5c2d-4c03-8026-1bad939d0d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/dit-base\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "np.object = np.object_\n",
    "np.int = np.int_\n",
    "np.bool = np.bool_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f463f52-80d9-4024-8056-1c7701cb3bb2",
   "metadata": {},
   "source": [
    "Tripletize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcc54ad-3678-4859-9320-3a23bacb1d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Triplet:\n",
    "    def __init__(self, train_folder):\n",
    "        self.train_folder = train_folder\n",
    "        self.labels = [label for label in os.listdir(train_folder) if label != '.ipynb_checkpoints']\n",
    "        self.label_to_path = {}\n",
    "        \n",
    "        for label in self.labels:\n",
    "            label_path = os.path.join(train_folder, label)\n",
    "            subdirectories = [subdir for subdir in os.listdir(label_path) if os.path.isdir(os.path.join(label_path, subdir))]\n",
    "            leaf_nodes = [os.path.join(label_path, subdir) for subdir in subdirectories if self.has_images(os.path.join(label_path, subdir))]\n",
    "            LEAF_NODES = []\n",
    "            for i in range(len(leaf_nodes)):\n",
    "                sub_sub = self.list_subfolders(leaf_nodes[i])\n",
    "                if sub_sub is not None:\n",
    "                    for patH in sub_sub:\n",
    "                        LEAF_NODES.append(os.path.join(leaf_nodes[i],patH))\n",
    "                else:\n",
    "                    LEAF_NODES.append(leaf_nodes[i])\n",
    "            self.label_to_path[label] = LEAF_NODES\n",
    "\n",
    "    def list_subfolders(self, folder_path):\n",
    "        if os.path.isdir(folder_path):\n",
    "            subfolders = [f.name for f in os.scandir(folder_path) if f.is_dir()]\n",
    "            if subfolders:\n",
    "                return subfolders\n",
    "            return None\n",
    "        return None\n",
    "\n",
    "    def has_images(self, directory):\n",
    "        # Check if the directory contains images\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            image_files = [file for file in files if file.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff', '.gif'))]\n",
    "            if image_files:\n",
    "                return True\n",
    "        return False\n",
    "    def get_triplet(self):\n",
    "        # Select anchor class with available images\n",
    "        anchor_label = random.choice([label for label in self.labels if any(self.label_to_path[label])])\n",
    "        anchor_subdir = random.choice(self.label_to_path[anchor_label])\n",
    "        anchor_image = self.get_random_image(anchor_subdir)\n",
    "\n",
    "        # Select positive example from the same class\n",
    "        positive_label = anchor_label\n",
    "        positive_subdir = anchor_subdir\n",
    "        positive_image = self.get_random_image(positive_subdir)\n",
    "\n",
    "        # Ensure the anchor and positive images are different\n",
    "        while anchor_image == positive_image:\n",
    "            positive_image = self.get_random_image(positive_subdir)\n",
    "\n",
    "        # Select negative example from a different class with available images\n",
    "        available_labels = [label for label in self.labels if label != anchor_label and any(self.label_to_path[label])]\n",
    "        negative_label = random.choice(available_labels)\n",
    "        negative_subdir = random.choice(self.label_to_path[negative_label])\n",
    "        negative_image = self.get_random_image(negative_subdir)\n",
    "\n",
    "        anchor_label_num = self.labels.index(anchor_label)\n",
    "        positive_label_num = self.labels.index(positive_label)\n",
    "        negative_label_num = self.labels.index(negative_label)\n",
    "\n",
    "        anchor_label_name = f\"{anchor_label}-{os.path.basename(anchor_subdir)}\"\n",
    "        positive_label_name = f\"{positive_label}-{os.path.basename(positive_subdir)}\"\n",
    "        negative_label_name = f\"{negative_label}-{os.path.basename(negative_subdir)}\"\n",
    "\n",
    "        return anchor_image, positive_image, negative_image, anchor_label_num, positive_label_num, negative_label_num, anchor_label_name, positive_label_name, negative_label_name\n",
    "\n",
    "    def get_random_image(self, directory):\n",
    "        # Recursively search for images in the directory\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            image_files = [file for file in files if file.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff', '.gif'))]\n",
    "            if image_files:\n",
    "                return os.path.join(root, random.choice(image_files))\n",
    "\n",
    "\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, train_folder, length, transform=None):\n",
    "        self.triplet_generator = Triplet(train_folder)\n",
    "        self.transform = transform\n",
    "        self.length = length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        anchor_image, positive_image, negative_image, anum, pnum, nnum, aname, pname, nname = self.triplet_generator.get_triplet()\n",
    "        anchor = self._load_image(anchor_image)\n",
    "        positive = self._load_image(positive_image)\n",
    "        negative = self._load_image(negative_image)\n",
    "\n",
    "        return anchor, positive, negative\n",
    "\n",
    "    def _load_image(self, image_path):\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def get_triplet_names(self, index):\n",
    "        anchor_image, positive_image, negative_image ,_ ,_, _, a,p,n= self.triplet_generator.get_triplet()\n",
    "        return anchor_image, positive_image, negative_image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    transforms.ToTensor(),           # Convert to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the tensor\n",
    "])\n",
    "\n",
    "TRAIN_FOLDER = \"./Datasets/DOCS-NEW/TRAIN\"\n",
    "TEST_FOLDER = \"./Datasets/DOCS-NEW/TEST\"\n",
    "bs = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe77de0-fd71-4c21-a3b4-1a78e76dfc0e",
   "metadata": {},
   "source": [
    "EMBEDDING NET WRAPPED BY TRIPLET NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49def49-b14a-492a-a334-2b5069e35506",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TEmbeddingNet(nn.Module):\n",
    "    def __init__(self, modelt):\n",
    "        super(TEmbeddingNet, self).__init__()\n",
    "        self.modelt = modelt\n",
    "        self.conv = nn.Conv1d(in_channels=197, out_channels=1, kernel_size=3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.modelt(x)  # Shape: (batch_size, 2048, H, W)\n",
    "        x = x.last_hidden_state\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "    def get_embedding(self, x):\n",
    "        x = self.modelt(x)  # Shape: (batch_size, 2048, H, W)\n",
    "        x = x.last_hidden_state\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "tmodel = TEmbeddingNet(model)\n",
    "\n",
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, embedding_net):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.enet = embedding_net\n",
    "\n",
    "    def forward(self, x1, x2=None, x3=None):\n",
    "        if x2 is None and x3 is None:\n",
    "            return self.enet.get_embedding(x1)\n",
    "        return self.enet.get_embedding(x1),self.enet.get_embedding(x2),self.enet.get_embedding(x3)\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.enet.get_embedding(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ee50c5-f5fe-42bd-8dc2-fb898fcf6223",
   "metadata": {},
   "source": [
    "TRIPLET LOSS AND MODEL INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e56ee39-61cb-4117-96a5-2c684d6ff222",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative, size_average=True):\n",
    "        distance_positive = torch.norm(anchor - positive, dim=1)\n",
    "        distance_negative = torch.norm(anchor - negative, dim=1)\n",
    "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean() if size_average else losses.sum()\n",
    "\n",
    "model = TripletNet(tmodel)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(TripletNet(tmodel))\n",
    "else:\n",
    "    model = TripletNet(tmodel)\n",
    "model = model.to(device)\n",
    "\n",
    "margin = 1\n",
    "lr = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=0.5)  # Learning rate scheduler\n",
    "loss_fn = TripletLoss(margin)\n",
    "clip_value = 0.5  # You can adjust this value as needed\n",
    "triplet_dataset = TripletDataset(TRAIN_FOLDER, length= int(input(\"TRIPLETS : \")), transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(triplet_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e438bdf1-146c-466c-8b40-519796d161f3",
   "metadata": {},
   "source": [
    "FIT THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7f695-6165-4d34-957a-1bbd954d804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, num_epochs, bs):\n",
    "    for epoch in range(n_epochs):\n",
    "        start = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for idx, batch in tqdm(enumerate(train_loader)):\n",
    "            anchor, positive, negative = batch\n",
    "            anchor = anchor.to(device)\n",
    "            positive = positive.to(device)\n",
    "            negative = negative.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            anchor_embedding, positive_embedding, negative_embedding = model(anchor, positive, negative)\n",
    "            anchor_embedding.requires_grad_(True)\n",
    "            positive_embedding.requires_grad_(True)\n",
    "            negative_embedding.requires_grad_(True)\n",
    "            loss = loss_fn(anchor_embedding, positive_embedding, negative_embedding)\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Train Loss: {train_loss / len(train_loader):.4f}, TIME: {time.time()-start}\")\n",
    "        torch.save(model.state_dict(), f\"model{epoch+1}.pth\")\n",
    "        scheduler.step()\n",
    "\n",
    "        \n",
    "fit(model, n_epochs:=int(input(\"NO OF EPOCHS : \")), bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa17f777-3cf9-45ac-b7c1-306db95d59e5",
   "metadata": {},
   "source": [
    "EXTRACT THE EMBEDDINGS AND EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94920d5d-c62a-428b-be8d-51d38c3b4306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform):\n",
    "        self.root_dir = root_dir\n",
    "        self.classes, self.class_to_idx = self._find_classes()\n",
    "        self.samples = self._make_dataset()\n",
    "        self.transform = transform\n",
    "\n",
    "    def _find_classes(self):\n",
    "        classes = [d for d in os.listdir(self.root_dir) if os.path.isdir(os.path.join(self.root_dir, d))]\n",
    "        classes.sort()\n",
    "        class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "    def _make_dataset(self):\n",
    "        samples = []\n",
    "        for target_class in self.classes:\n",
    "            class_dir = os.path.join(self.root_dir, target_class)\n",
    "            for root, dirs, files in os.walk(class_dir):\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif','.tif','.tiff')):\n",
    "                        path = os.path.join(root, file)\n",
    "                        rel_path = os.path.relpath(path, self.root_dir)\n",
    "                        samples.append((path, target_class, rel_path.split(os.path.sep)))\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, target_class, rel_path = self.samples[index]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        return img, target_class, rel_path\n",
    "\n",
    "train_dataloader = DataLoader(CustomDataset(TRAIN_FOLDER,transform=transform))\n",
    "test_dataloader = DataLoader(CustomDataset(TEST_FOLDER,transform=transform))\n",
    "\n",
    "def xtract(loader):\n",
    "    LABELS = []\n",
    "    embs = None\n",
    "    print(\"EXTRACTING EMBS...\")\n",
    "    for i in tqdm(loader):\n",
    "        img, cls, path = i\n",
    "        if len(path)==4:\n",
    "            LABELS.append([cls[0], path[1][0], path[2][0]])\n",
    "        else:\n",
    "            LABELS.append([cls[0], path[1][0]])\n",
    "        emb = model(img.to(device)).detach()\n",
    "        if embs is None:\n",
    "            embs = emb\n",
    "        else:\n",
    "            embs = torch.cat((embs, emb), dim=0)\n",
    "    return embs, LABELS\n",
    "\n",
    "trainembs, trainlabs = xtract(train_dataloader)\n",
    "testembs, testlabs = xtract(test_dataloader)\n",
    "\n",
    "print(\"INDEX BEING CREATED....\")\n",
    "embs_cpu_np = trainembs.cpu().numpy()\n",
    "del trainembs\n",
    "embs_cpu_np = embs_cpu_np.reshape(embs_cpu_np.shape[0], -1)\n",
    "index = faiss.IndexHNSWFlat(embs_cpu_np.shape[1], 32)  # M = 32 for the HNSW index\n",
    "index.add(embs_cpu_np)\n",
    "print(\"INDEX CREATED....\")\n",
    "\n",
    "#Evaluate\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def print_accuracy_table(accuracy_dict):\n",
    "    keys = list(accuracy_dict.keys())\n",
    "\n",
    "    # Create a table with the keys in the first row and first column\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [''] + keys\n",
    "\n",
    "    # Fill in the table with accuracy values\n",
    "    for key_row in keys:\n",
    "        row_data = [key_row]\n",
    "        for key_col in keys:\n",
    "            if key_col in accuracy_dict[key_row]:\n",
    "                accuracy = f'{accuracy_dict[key_row][key_col]:.2f}%'\n",
    "            else:\n",
    "                accuracy = '0%'\n",
    "            row_data.append(accuracy)\n",
    "\n",
    "        table.add_row(row_data)\n",
    "\n",
    "    # Print the table\n",
    "    print(table)\n",
    "\n",
    "def tempimgcount(root_dir):\n",
    "    count = 0\n",
    "\n",
    "    for first_level_folder in os.listdir(root_dir):\n",
    "        first_level_path = os.path.join(root_dir, first_level_folder)\n",
    "\n",
    "        if os.path.isdir(first_level_path):\n",
    "            for second_level_folder in os.listdir(first_level_path):\n",
    "                second_level_path = os.path.join(first_level_path, second_level_folder)\n",
    "\n",
    "                if os.path.isdir(second_level_path):\n",
    "                    for third_level_folder in os.listdir(second_level_path):\n",
    "                        third_level_path = os.path.join(second_level_path, third_level_folder)\n",
    "\n",
    "                        if os.path.isdir(third_level_path):\n",
    "                            # Assuming images have common extensions like .png, .jpg, .jpeg\n",
    "                            image_files = [file for file in os.listdir(third_level_path) if file.lower().endswith(('.png', '.jpg','.tif','.jpeg'))]\n",
    "                            count += len(image_files)\n",
    "\n",
    "    return count\n",
    "\n",
    "temp_img_count = tempimgcount(TEST_FOLDER)\n",
    "\n",
    "def count_imgs_in_folder(folder_path):\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.tiff', '.gif', '.tif']  # Add more extensions if needed\n",
    "    image_count = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "                image_count += 1\n",
    "\n",
    "    return image_count\n",
    "\n",
    "def percentage(d):\n",
    "    D = d\n",
    "    for key in d:\n",
    "        LEN = count_imgs_in_folder(os.path.join(TEST_FOLDER,key))\n",
    "        for clss in d[key]:\n",
    "            D[key][clss] = d[key][clss]/LEN*100\n",
    "    return D\n",
    "\n",
    "def evaluate_with_faiss(embs, index):\n",
    "    outer_class_wise = {}\n",
    "    inner_class_wise = {}\n",
    "    outer_wrongly = {}\n",
    "    inner_wrongly = {}\n",
    "    TOTAL = len(embs)\n",
    "    start = time.time()\n",
    "    tempwise = 0\n",
    "    outer = 0\n",
    "    inner = 0\n",
    "    # Initialize the tqdm progress bar\n",
    "    with tqdm(total=TOTAL) as pbar:\n",
    "        for idx, emb in enumerate(embs):\n",
    "            #search\n",
    "            label = index.search(emb.reshape(1, -1), 1)[1][0][0]\n",
    "            #percentage of predictions\n",
    "            if testlabs[idx][0] not in outer_wrongly:\n",
    "                outer_wrongly[testlabs[idx][0]] = {testlabs[idx][0]:0}\n",
    "            if trainlabs[label][0] not in outer_wrongly[testlabs[idx][0]]: \n",
    "                outer_wrongly[testlabs[idx][0]][trainlabs[label][0]] = 1\n",
    "            else:\n",
    "                outer_wrongly[testlabs[idx][0]][trainlabs[label][0]] += 1\n",
    "                \n",
    "            if testlabs[idx][1] not in inner_wrongly:\n",
    "                inner_wrongly[testlabs[idx][1]] = {testlabs[idx][1]:0}\n",
    "            \n",
    "            if trainlabs[label][1] not in inner_wrongly[testlabs[idx][1]]:\n",
    "                inner_wrongly[testlabs[idx][1]][trainlabs[label][1]] = 1\n",
    "            else:\n",
    "                inner_wrongly[testlabs[idx][1]][trainlabs[label][1]]+=1\n",
    "\n",
    "            if trainlabs[label][0] == testlabs[idx][0]:\n",
    "                if testlabs[idx][0] not in outer_class_wise:\n",
    "                    outer_class_wise[testlabs[idx][0]]=1\n",
    "                else:\n",
    "                    outer_class_wise[testlabs[idx][0]]+=1\n",
    "                    \n",
    "                outer += 1\n",
    "                if trainlabs[label][1] == testlabs[idx][1]:\n",
    "                    if testlabs[idx][1] not in inner_class_wise:\n",
    "                        inner_class_wise[testlabs[idx][1]]=1\n",
    "                    else:\n",
    "                        inner_class_wise[testlabs[idx][1]]+=1\n",
    "                    inner += 1\n",
    "                    if len(trainlabs[label])==3 and len(testlabs[idx])==3 and trainlabs[label][2]==testlabs[idx][2]:\n",
    "                        tempwise+=1\n",
    "            pbar.update(1)  # Update the progress bar\n",
    "    oaccuracy = (outer / TOTAL) * 100\n",
    "    iaccuracy = (inner / TOTAL) * 100\n",
    "    taccuracy = (tempwise / temp_img_count) * 100\n",
    "    elapsed_time = time.time() - start\n",
    "    print_accuracy_table(percentage(outer_wrongly))\n",
    "    return f'OUTER Accuracy: {oaccuracy:.2f}%, INNER Accuracy: {iaccuracy:.2f}%, TEMPWISE Accuracy: {taccuracy:.2f}% '\n",
    "\n",
    "embs2_cpu_np = testembs.cpu().numpy()\n",
    "embs2_cpu_np = embs2_cpu_np.reshape(embs2_cpu_np.shape[0], -1)\n",
    "print(f'IndexHNSWFlat : {evaluate_with_faiss(embs2_cpu_np,index)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
